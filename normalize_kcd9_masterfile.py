"""
KCD-9 Master file ì •ê·œí™” ë° JSON ë³€í™˜
- 54,126ê°œ ì§ˆë³‘ì½”ë“œë¥¼ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜
- ê²€ìƒ‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬
"""
import sys
import codecs
from pathlib import Path
import pandas as pd
import json
from datetime import datetime

# UTF-8 ì¶œë ¥
if sys.platform == 'win32':
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')


def normalize_masterfile():
    """Master file ì •ê·œí™”"""

    file_path = Path('data/kssc/kcd-9th/ì œ9ì°¨ í•œêµ­í‘œì¤€ì§ˆë³‘ã†ì‚¬ì¸ë¶„ë¥˜ 2ì°¨ ì •ì˜¤ DB masterfile_251031_20251103085142.xlsx')
    output_dir = Path('data/kssc/kcd-9th/normalized')
    output_dir.mkdir(exist_ok=True, parents=True)

    print('='*80)
    print('ğŸ”„ KCD-9 Master File ì •ê·œí™”')
    print('='*80)
    print(f'\nì…ë ¥: {file_path.name}')
    print(f'ì¶œë ¥: {output_dir}\n')

    # Master file ì½ê¸° (2í–‰ì´ í—¤ë”)
    df = pd.read_excel(file_path, sheet_name='KCD-8 DB Masterfile', header=2)

    print(f'ì´ ë°ì´í„°: {len(df):,}ê°œ í–‰\n')

    # ì»¬ëŸ¼ëª… ì •ë¦¬
    df.columns = [
        'is_header',        # í‘œì œì–´ (1ì´ë©´ ì£¼ ì½”ë“œ)
        'classification',   # ë¶„ë¥˜ê¸°ì¤€ (ëŒ€/ì¤‘/ì†Œ/ì„¸)
        'code',            # ì§ˆë³‘ë¶„ë¥˜ì½”ë“œ
        'symbol',          # ê²€ë³„ (+/*)
        'note',            # ì£¼ì„ (í¬í•¨/ì œì™¸/ì£¼)
        'name_kr',         # í•œê¸€ëª…ì¹­
        'name_en',         # ì˜ë¬¸ëª…ì¹­
        'is_lowest',       # ìµœí•˜ìœ„ì½”ë“œ (1ì´ë©´ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥)
        'is_domestic',     # êµ­ë‚´ì„¸ë¶„í™”ì½”ë“œ
        'is_oriental',     # í•œì˜ë³‘ëª…
        'is_additional',   # êµ­ë‚´ì¶”ê°€ì§„ë‹¨ëª…
        'revision_no',     # ì •ì˜¤ì°¨ìˆ˜
        'revision_note',   # ì •ì˜¤ë‚´ìš©
        'unused'           # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼
    ]

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = df.fillna({
        'is_header': 0,
        'classification': '',
        'symbol': '',
        'note': '',
        'is_lowest': 0,
        'is_domestic': 0,
        'is_oriental': 0,
        'is_additional': 0,
    })

    # ë°ì´í„° íƒ€ì… ë³€í™˜
    df['is_header'] = df['is_header'].astype(int)
    df['is_lowest'] = df['is_lowest'].astype(int)
    df['is_domestic'] = df['is_domestic'].astype(int)
    df['is_oriental'] = df['is_oriental'].astype(int)
    df['is_additional'] = df['is_additional'].astype(int)

    print('[ë°ì´í„° ì •ì œ ì™„ë£Œ]')
    print(f'  - ì»¬ëŸ¼ëª… ì •ë¦¬')
    print(f'  - ê²°ì¸¡ì¹˜ ì²˜ë¦¬')
    print(f'  - ë°ì´í„° íƒ€ì… ë³€í™˜\n')

    # í†µê³„
    print('[ë°ì´í„° í†µê³„]')
    print(f'  ì´ ì½”ë“œ ìˆ˜: {len(df):,}ê°œ')
    print(f'  í‘œì œì–´ (ì£¼ ì½”ë“œ): {df["is_header"].sum():,}ê°œ')
    print(f'  ìµœí•˜ìœ„ ì½”ë“œ (ì‚¬ìš© ê°€ëŠ¥): {df["is_lowest"].sum():,}ê°œ')
    print(f'  êµ­ë‚´ ì„¸ë¶„í™”: {df["is_domestic"].sum():,}ê°œ')
    print(f'  í•œì˜ ë³‘ëª…: {df["is_oriental"].sum():,}ê°œ')
    print(f'  êµ­ë‚´ ì¶”ê°€: {df["is_additional"].sum():,}ê°œ')

    # ë¶„ë¥˜ ë ˆë²¨ í†µê³„
    print(f'\n[ë¶„ë¥˜ ì²´ê³„]')
    classification_counts = df[df['classification'] != '']['classification'].value_counts()
    for level, count in classification_counts.items():
        print(f'  {level}: {count:,}ê°œ')

    # ê²€ë³„ í†µê³„
    symbol_counts = df[df['symbol'] != '']['symbol'].value_counts()
    print(f'\n[ê²€ë³„ í‘œì‹œ]')
    for symbol, count in symbol_counts.items():
        print(f'  {symbol}: {count:,}ê°œ')

    # 1. ì „ì²´ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    print(f'\n[1] ì „ì²´ ë°ì´í„° JSON ë³€í™˜...')

    records = []
    for _, row in df.iterrows():
        record = {
            'code': str(row['code']).strip(),
            'name_kr': str(row['name_kr']).strip() if pd.notna(row['name_kr']) else '',
            'name_en': str(row['name_en']).strip() if pd.notna(row['name_en']) else '',
            'is_header': bool(row['is_header']),
            'classification': str(row['classification']).strip(),
            'symbol': str(row['symbol']).strip(),
            'note': str(row['note']).strip() if pd.notna(row['note']) else '',
            'is_lowest': bool(row['is_lowest']),
            'is_domestic': bool(row['is_domestic']),
            'is_oriental': bool(row['is_oriental']),
            'is_additional': bool(row['is_additional']),
        }

        # ì •ì˜¤ ì •ë³´ (ìˆëŠ” ê²½ìš°ë§Œ)
        if pd.notna(row['revision_no']):
            record['revision'] = {
                'no': str(row['revision_no']).strip(),
                'note': str(row['revision_note']).strip() if pd.notna(row['revision_note']) else ''
            }

        records.append(record)

    # ì „ì²´ ë°ì´í„° ì €ì¥
    full_output = {
        'version': 'KCD-9',
        'release_date': '2025-10-31',
        'revision': '2ì°¨ ì •ì˜¤',
        'total_codes': len(records),
        'generated_at': datetime.now().isoformat(),
        'codes': records
    }

    full_file = output_dir / 'kcd9_full.json'
    with open(full_file, 'w', encoding='utf-8') as f:
        json.dump(full_output, f, ensure_ascii=False, indent=2)

    print(f'  âœ… ì €ì¥: {full_file.name} ({len(records):,}ê°œ ì½”ë“œ)')

    # 2. ìµœí•˜ìœ„ ì½”ë“œë§Œ ì¶”ì¶œ (ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ë“œ)
    print(f'\n[2] ìµœí•˜ìœ„ ì½”ë“œë§Œ ì¶”ì¶œ...')

    lowest_df = df[df['is_lowest'] == 1].copy()
    lowest_records = []

    for _, row in lowest_df.iterrows():
        record = {
            'code': str(row['code']).strip(),
            'name_kr': str(row['name_kr']).strip() if pd.notna(row['name_kr']) else '',
            'name_en': str(row['name_en']).strip() if pd.notna(row['name_en']) else '',
            'classification': str(row['classification']).strip(),
            'symbol': str(row['symbol']).strip(),
            'is_domestic': bool(row['is_domestic']),
            'is_oriental': bool(row['is_oriental']),
        }
        lowest_records.append(record)

    lowest_output = {
        'version': 'KCD-9',
        'release_date': '2025-10-31',
        'revision': '2ì°¨ ì •ì˜¤',
        'description': 'ìµœí•˜ìœ„ ì½”ë“œë§Œ í¬í•¨ (ì‹¤ì œ ì§„ë‹¨ ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ë“œ)',
        'total_codes': len(lowest_records),
        'generated_at': datetime.now().isoformat(),
        'codes': lowest_records
    }

    lowest_file = output_dir / 'kcd9_usable_codes.json'
    with open(lowest_file, 'w', encoding='utf-8') as f:
        json.dump(lowest_output, f, ensure_ascii=False, indent=2)

    print(f'  âœ… ì €ì¥: {lowest_file.name} ({len(lowest_records):,}ê°œ ì½”ë“œ)')

    # 3. ì½”ë“œ â†’ ëª…ì¹­ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ (ë¹ ë¥¸ ê²€ìƒ‰ìš©)
    print(f'\n[3] ê²€ìƒ‰ìš© ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±...')

    code_map = {}
    for _, row in df.iterrows():
        code = str(row['code']).strip()
        code_map[code] = {
            'name_kr': str(row['name_kr']).strip() if pd.notna(row['name_kr']) else '',
            'name_en': str(row['name_en']).strip() if pd.notna(row['name_en']) else '',
            'is_lowest': bool(row['is_lowest']),
            'is_header': bool(row['is_header']),
        }

    map_output = {
        'version': 'KCD-9',
        'description': 'ì½”ë“œ â†’ ëª…ì¹­ ë¹ ë¥¸ ê²€ìƒ‰ìš© ë§¤í•‘',
        'total_codes': len(code_map),
        'generated_at': datetime.now().isoformat(),
        'map': code_map
    }

    map_file = output_dir / 'kcd9_code_map.json'
    with open(map_file, 'w', encoding='utf-8') as f:
        json.dump(map_output, f, ensure_ascii=False, indent=2)

    print(f'  âœ… ì €ì¥: {map_file.name} ({len(code_map):,}ê°œ ì½”ë“œ)')

    # 4. ëŒ€ë¶„ë¥˜ë³„ í†µê³„
    print(f'\n[4] ëŒ€ë¶„ë¥˜ë³„ í†µê³„ ìƒì„±...')

    major_df = df[df['classification'] == 'ëŒ€'].copy()
    major_stats = []

    for _, row in major_df.iterrows():
        code_range = str(row['code']).strip()
        name_kr = str(row['name_kr']).strip() if pd.notna(row['name_kr']) else ''

        # í•´ë‹¹ ëŒ€ë¶„ë¥˜ì— ì†í•˜ëŠ” ì½”ë“œ ìˆ˜ ê³„ì‚°
        # ì˜ˆ: A00-B99 â†’ A, Bë¡œ ì‹œì‘í•˜ëŠ” ì½”ë“œë“¤
        start_code = code_range.split('-')[0][0] if '-' in code_range else code_range[0]

        count = len(df[df['code'].astype(str).str.startswith(start_code)])

        major_stats.append({
            'code_range': code_range,
            'name_kr': name_kr,
            'total_codes': count
        })

    stats_output = {
        'version': 'KCD-9',
        'description': 'ëŒ€ë¶„ë¥˜(Chapter)ë³„ í†µê³„',
        'generated_at': datetime.now().isoformat(),
        'chapters': major_stats
    }

    stats_file = output_dir / 'kcd9_statistics.json'
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats_output, f, ensure_ascii=False, indent=2)

    print(f'  âœ… ì €ì¥: {stats_file.name} ({len(major_stats)}ê°œ ëŒ€ë¶„ë¥˜)')

    # ìš”ì•½
    print(f'\n\n{"="*80}')
    print('ğŸ“Š ì •ê·œí™” ì™„ë£Œ ìš”ì•½')
    print('='*80)
    print(f'\nìƒì„±ëœ íŒŒì¼:')
    print(f'  1. kcd9_full.json - ì „ì²´ ë°ì´í„° ({len(records):,}ê°œ)')
    print(f'  2. kcd9_usable_codes.json - ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ë“œ ({len(lowest_records):,}ê°œ)')
    print(f'  3. kcd9_code_map.json - ë¹ ë¥¸ ê²€ìƒ‰ìš© ({len(code_map):,}ê°œ)')
    print(f'  4. kcd9_statistics.json - ëŒ€ë¶„ë¥˜ í†µê³„ ({len(major_stats)}ê°œ)')

    print(f'\nğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_dir}')

    return {
        'full': full_file,
        'usable': lowest_file,
        'map': map_file,
        'stats': stats_file
    }


def main():
    files = normalize_masterfile()

    print('\n\n' + '='*80)
    print('âœ… ì™„ë£Œ')
    print('='*80)

    # ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print('\n[ê²€ìƒ‰ í…ŒìŠ¤íŠ¸]')

    with open(files['map'], 'r', encoding='utf-8') as f:
        data = json.load(f)
        code_map = data['map']

    # ìƒ˜í”Œ ì½”ë“œ ê²€ìƒ‰
    test_codes = ['A00', 'A00.0', 'I10', 'C50']

    for code in test_codes:
        if code in code_map:
            info = code_map[code]
            usable = 'âœ…' if info['is_lowest'] else 'âŒ'
            print(f'  {code}: {info["name_kr"]} {usable}')
        else:
            print(f'  {code}: ì½”ë“œ ì—†ìŒ')


if __name__ == '__main__':
    main()
