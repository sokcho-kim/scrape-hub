"""
KDRG ë¶„ë¥˜ì§‘ ëª©ì°¨ ì¶”ì¶œ ë° êµ¬ì¡° ë¶„ì„
PyMuPDF(fitz)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª©ì°¨ì™€ ì„¹ì…˜ êµ¬ì¡° íŒŒì•…
"""
import sys
import codecs
from pathlib import Path
import json
import fitz  # PyMuPDF

# UTF-8 ì¶œë ¥
if sys.platform == 'win32':
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')


def extract_toc(pdf_path: Path):
    """PDFì—ì„œ ëª©ì°¨(TOC) ì¶”ì¶œ"""

    print('='*80)
    print('ğŸ“š KDRG ë¶„ë¥˜ì§‘ ëª©ì°¨ ì¶”ì¶œ')
    print('='*80)
    print(f'\níŒŒì¼: {pdf_path.name}\n')

    # PDF ì—´ê¸°
    doc = fitz.open(pdf_path)
    total_pages = len(doc)

    print(f'ì´ í˜ì´ì§€: {total_pages}p\n')

    # 1. ë‚´ì¥ëœ TOC ì¶”ì¶œ
    print('[1] ë‚´ì¥ ëª©ì°¨(TOC) ì¶”ì¶œ')
    toc = doc.get_toc()

    if toc:
        print(f'  âœ… {len(toc)}ê°œ í•­ëª© ë°œê²¬\n')

        # ëª©ì°¨ êµ¬ì¡° ì¶œë ¥
        print('[ëª©ì°¨ êµ¬ì¡° (ì²˜ìŒ 50ê°œ)]')
        for i, item in enumerate(toc[:50], 1):
            level, title, page = item
            indent = '  ' * (level - 1)
            print(f'{i:3d}. {indent}[Lv{level}] {title} (p.{page})')

        if len(toc) > 50:
            print(f'\n... (ì´ {len(toc)}ê°œ ì¤‘ 50ê°œë§Œ í‘œì‹œ)')
    else:
        print('  âŒ ë‚´ì¥ ëª©ì°¨ ì—†ìŒ')
        print('  ğŸ’¡ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ëª©ì°¨ ì¶”ì¶œ ì‹œë„...\n')

        # ë‚´ì¥ TOCê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
        toc = extract_toc_from_text(doc)

    # 2. MDC êµ¬ì¡° ë¶„ì„
    print(f'\n\n[2] MDC êµ¬ì¡° ë¶„ì„')

    mdc_sections = []
    current_mdc = None

    for item in toc:
        level, title, page = item

        # MDC 01, MDC 02 ë“±ì˜ íŒ¨í„´ ì°¾ê¸°
        if 'MDC' in title and level <= 2:
            if current_mdc:
                mdc_sections.append(current_mdc)

            current_mdc = {
                'title': title,
                'start_page': page,
                'end_page': None,
                'subsections': []
            }
        elif current_mdc and level <= 3:
            # MDCì˜ í•˜ìœ„ ì„¹ì…˜
            current_mdc['subsections'].append({
                'title': title,
                'page': page,
                'level': level
            })

    # ë§ˆì§€ë§‰ MDC ì¶”ê°€
    if current_mdc:
        mdc_sections.append(current_mdc)

    # MDC ì¢…ë£Œ í˜ì´ì§€ ê³„ì‚°
    for i, mdc in enumerate(mdc_sections):
        if i < len(mdc_sections) - 1:
            mdc['end_page'] = mdc_sections[i + 1]['start_page'] - 1
        else:
            mdc['end_page'] = total_pages

    # MDC í†µê³„
    print(f'  ë°œê²¬ëœ MDC: {len(mdc_sections)}ê°œ\n')

    for i, mdc in enumerate(mdc_sections[:10], 1):
        pages = mdc['end_page'] - mdc['start_page'] + 1
        subsec_count = len(mdc['subsections'])
        print(f'  {i:2d}. {mdc["title"]:50s} p.{mdc["start_page"]:4d}-{mdc["end_page"]:4d} ({pages:3d}p, {subsec_count:2d}ê°œ í•˜ìœ„ì„¹ì…˜)')

    if len(mdc_sections) > 10:
        print(f'\n  ... (ì´ {len(mdc_sections)}ê°œ ì¤‘ 10ê°œë§Œ í‘œì‹œ)')

    # 3. ë¶„í•  ì „ëµ ì œì•ˆ
    print(f'\n\n[3] ì§€ëŠ¥í˜• ë¶„í•  ì „ëµ ì œì•ˆ')

    target_chunk_size = 50  # ëª©í‘œ ì²­í¬ í¬ê¸°
    suggested_chunks = []

    for mdc in mdc_sections:
        pages = mdc['end_page'] - mdc['start_page'] + 1

        # MDCê°€ target_chunk_sizeë³´ë‹¤ ì‘ìœ¼ë©´ ê·¸ëŒ€ë¡œ
        if pages <= target_chunk_size:
            suggested_chunks.append({
                'name': mdc['title'],
                'start': mdc['start_page'],
                'end': mdc['end_page'],
                'pages': pages,
                'type': 'mdc'
            })
        else:
            # MDCê°€ í¬ë©´ í•˜ìœ„ì„¹ì…˜ìœ¼ë¡œ ë¶„í• 
            if mdc['subsections']:
                # í•˜ìœ„ì„¹ì…˜ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
                for j, subsec in enumerate(mdc['subsections']):
                    if j < len(mdc['subsections']) - 1:
                        end = mdc['subsections'][j + 1]['page'] - 1
                    else:
                        end = mdc['end_page']

                    sub_pages = end - subsec['page'] + 1

                    suggested_chunks.append({
                        'name': f"{mdc['title']} - {subsec['title']}",
                        'start': subsec['page'],
                        'end': end,
                        'pages': sub_pages,
                        'type': 'subsection'
                    })
            else:
                # í•˜ìœ„ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ê· ë“± ë¶„í• 
                num_chunks = (pages + target_chunk_size - 1) // target_chunk_size
                chunk_size = pages // num_chunks

                for j in range(num_chunks):
                    start = mdc['start_page'] + j * chunk_size
                    end = min(start + chunk_size - 1, mdc['end_page'])

                    suggested_chunks.append({
                        'name': f"{mdc['title']} Part {j+1}",
                        'start': start,
                        'end': end,
                        'pages': end - start + 1,
                        'type': 'split'
                    })

    print(f'  ì œì•ˆëœ ì²­í¬ ìˆ˜: {len(suggested_chunks)}ê°œ')
    print(f'  í‰ê·  í˜ì´ì§€: {sum(c["pages"] for c in suggested_chunks) / len(suggested_chunks):.1f}p\n')

    # ì²­í¬ë³„ ìƒì„¸ ì •ë³´
    print('[ì œì•ˆëœ ë¶„í•  (ì²˜ìŒ 20ê°œ)]')
    for i, chunk in enumerate(suggested_chunks[:20], 1):
        chunk_type = {'mdc': 'ğŸ“š', 'subsection': 'ğŸ“–', 'split': 'ğŸ“„'}[chunk['type']]
        print(f'  {i:2d}. {chunk_type} {chunk["name"]:60s} p.{chunk["start"]:4d}-{chunk["end"]:4d} ({chunk["pages"]:3d}p)')

    if len(suggested_chunks) > 20:
        print(f'\n  ... (ì´ {len(suggested_chunks)}ê°œ ì¤‘ 20ê°œë§Œ í‘œì‹œ)')

    # 4. ê²°ê³¼ ì €ì¥
    output = {
        'source_file': pdf_path.name,
        'total_pages': total_pages,
        'toc_entries': len(toc),
        'mdc_count': len(mdc_sections),
        'suggested_chunks': len(suggested_chunks),
        'toc': [{'level': item[0], 'title': item[1], 'page': item[2]} for item in toc],
        'mdc_sections': mdc_sections,
        'suggested_chunks': suggested_chunks
    }

    output_file = Path('data/hira_master/kdrg_structure.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f'\n\nğŸ’¾ êµ¬ì¡° ì •ë³´ ì €ì¥: {output_file}')

    doc.close()

    return output


def extract_toc_from_text(doc):
    """í…ìŠ¤íŠ¸ì—ì„œ ëª©ì°¨ ì¶”ì¶œ (ë‚´ì¥ TOCê°€ ì—†ì„ ê²½ìš°)"""

    print('  [í…ìŠ¤íŠ¸ ê¸°ë°˜ ëª©ì°¨ ì¶”ì¶œ]')

    toc = []

    # ëª©ì°¨ í˜ì´ì§€ ì¶”ì • (ë³´í†µ ì²˜ìŒ 20í˜ì´ì§€ ë‚´)
    for page_num in range(min(30, len(doc))):
        page = doc[page_num]
        text = page.get_text()

        lines = text.split('\n')

        for line in lines:
            line = line.strip()

            # MDC íŒ¨í„´ ì°¾ê¸°
            if line.startswith('MDC') or 'ADRG' in line or 'PreMDC' in line:
                # í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„
                parts = line.split('Â·Â·Â·')
                if len(parts) >= 2:
                    try:
                        page_no = int(parts[-1].strip())
                        title = parts[0].strip()
                        toc.append([1, title, page_no])
                    except:
                        pass

    print(f'    âœ… {len(toc)}ê°œ í•­ëª© ì¶”ì¶œ')

    return toc


def main():
    pdf_path = Path('data/hira_master/KDRG ë¶„ë¥˜ì§‘(ì‹ í¬ê´„ì§€ë¶ˆì œë„ìš© ver1.4).pdf')

    if not pdf_path.exists():
        print(f'âŒ íŒŒì¼ ì—†ìŒ: {pdf_path}')
        return

    result = extract_toc(pdf_path)

    print('\n\n' + '='*80)
    print('âœ… ì™„ë£Œ')
    print('='*80)

    print(f'\nğŸ“Š ìš”ì•½:')
    print(f'  - ì´ í˜ì´ì§€: {result["total_pages"]:,}p')
    print(f'  - ëª©ì°¨ í•­ëª©: {result["toc_entries"]:,}ê°œ')
    print(f'  - MDC ì„¹ì…˜: {result["mdc_count"]}ê°œ')
    print(f'  - ì œì•ˆ ì²­í¬: {result["suggested_chunks"]}ê°œ')
    print(f'  - í‰ê·  ì²­í¬ í¬ê¸°: {sum(c["pages"] for c in result["suggested_chunks"]) / len(result["suggested_chunks"]):.1f}p')


if __name__ == '__main__':
    main()
