import pandas as pd
import json
import os
from pathlib import Path

def analyze_file(filepath):
    """íŒŒì¼ì„ ë¶„ì„í•´ì„œ ë©”íƒ€ì •ë³´ ë°˜í™˜"""
    filename = os.path.basename(filepath)
    filesize = os.path.getsize(filepath)
    ext = filepath.suffix

    info = {
        'filename': filename,
        'size': f"{filesize / 1024:.1f} KB",
        'type': None,
        'rows': None,
        'columns': None,
        'description': None
    }

    try:
        if ext == '.csv':
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            info['type'] = 'CSV'
            info['rows'] = len(df)
            info['columns'] = list(df.columns)
            info['column_count'] = len(df.columns)
        elif ext == '.json':
            with open(filepath, encoding='utf-8') as f:
                data = json.load(f)
            info['type'] = 'JSON'
            if isinstance(data, list):
                info['rows'] = len(data)
                if len(data) > 0 and isinstance(data[0], dict):
                    info['columns'] = list(data[0].keys())
                    info['column_count'] = len(data[0].keys())
            elif isinstance(data, dict):
                info['rows'] = len(data)
                info['structure'] = 'Dictionary'
    except Exception as e:
        info['error'] = str(e)

    return info

# bridges í´ë”ì˜ ëª¨ë“  ë°ì´í„° íŒŒì¼ ë¶„ì„
bridge_files = sorted(Path('.').glob('*.csv')) + sorted(Path('.').glob('*.json'))

print("=" * 100)
print("BRIDGES í´ë” ë°ì´í„° ìƒ‰ì¸")
print("=" * 100)

data_files = []
script_files = []

for filepath in bridge_files:
    if 'sample' in filepath.name:
        continue  # ìƒ˜í”Œ íŒŒì¼ì€ ë‚˜ì¤‘ì— ë”°ë¡œ ì²˜ë¦¬
    info = analyze_file(filepath)
    data_files.append(info)

# íŒŒì¼ë³„ ìƒì„¸ ì •ë³´ ì¶œë ¥
print("\n## ğŸ“Š ë°ì´í„° íŒŒì¼ ëª©ë¡\n")

categories = {
    'master': [],
    'clean': [],
    'normalized': [],
    'sample': []
}

# íŒŒì¼ ë¶„ë¥˜
for f in data_files:
    if 'sample' in f['filename']:
        categories['sample'].append(f)
    elif 'normalized' in f['filename']:
        categories['normalized'].append(f)
    elif 'clean' in f['filename']:
        categories['clean'].append(f)
    elif 'master' in f['filename']:
        categories['master'].append(f)

# 1. Master íŒŒì¼ (ì›ë³¸ í†µí•©)
print("### 1ï¸âƒ£ MASTER - ì›ë³¸ í†µí•© ë°ì´í„°")
print("ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ í•­ì•”ì œ ë°ì´í„°ë¥¼ ATC ì½”ë“œ ê¸°ë°˜ìœ¼ë¡œ í†µí•©í•œ 1ì°¨ ê²°ê³¼ë¬¼")
print("-" * 100)
for f in categories['master']:
    print(f"\nğŸ“„ **{f['filename']}** ({f['size']})")
    print(f"   - í˜•ì‹: {f['type']}")
    print(f"   - í–‰ ìˆ˜: {f['rows']:,}ê°œ")
    if f.get('columns'):
        print(f"   - ì»¬ëŸ¼: {f['column_count']}ê°œ")
        print(f"     {', '.join(f['columns'][:8])}")
        if len(f['columns']) > 8:
            print(f"     {', '.join(f['columns'][8:])}")

# 2. Clean íŒŒì¼ (ì •ì œ)
print("\n\n### 2ï¸âƒ£ CLEAN - ì •ì œ ë°ì´í„°")
print("ë¸Œëœë“œëª…, ì„±ë¶„ëª… ì¶”ì¶œ ë° ì •ì œê°€ ì™„ë£Œëœ ë°ì´í„° (Phase 1)")
print("-" * 100)
for f in categories['clean']:
    print(f"\nğŸ“„ **{f['filename']}** ({f['size']})")
    print(f"   - í˜•ì‹: {f['type']}")
    print(f"   - í–‰ ìˆ˜: {f['rows']:,}ê°œ")
    if f.get('columns'):
        print(f"   - ì»¬ëŸ¼: {f['column_count']}ê°œ")
        print(f"     {', '.join(f['columns'][:8])}")
        if len(f['columns']) > 8:
            print(f"     {', '.join(f['columns'][8:])}")

# 3. Normalized íŒŒì¼ (ì •ê·œí™”)
print("\n\n### 3ï¸âƒ£ NORMALIZED - ì •ê·œí™” ë°ì´í„° (ìµœì¢…)")
print("1 ì œí’ˆ = 1 í–‰ êµ¬ì¡°ë¡œ ì •ê·œí™”, HIRA dictionaryì™€ ì¡°ì¸í•˜ì—¬ ì œì¡°ì‚¬/ì•½ê°€ ì •ë³´ ì¶”ê°€")
print("-" * 100)
for f in categories['normalized']:
    print(f"\nğŸ“„ **{f['filename']}** ({f['size']})")
    print(f"   - í˜•ì‹: {f['type']}")
    print(f"   - í–‰ ìˆ˜: {f['rows']:,}ê°œ")
    if f.get('columns'):
        print(f"   - ì»¬ëŸ¼: {f['column_count']}ê°œ")
        print(f"     {', '.join(f['columns'][:8])}")
        if len(f['columns']) > 8:
            print(f"     {', '.join(f['columns'][8:])}")

# ìƒ˜í”Œ íŒŒì¼
sample_files = sorted(Path('.').glob('*sample*.json'))
if sample_files:
    print("\n\n### 4ï¸âƒ£ SAMPLE - ìƒ˜í”Œ íŒŒì¼")
    print("ë°ì´í„° êµ¬ì¡° í™•ì¸ìš© ìƒ˜í”Œ (5-10ê°œ ë ˆì½”ë“œ)")
    print("-" * 100)
    for filepath in sample_files:
        info = analyze_file(filepath)
        print(f"\nğŸ“„ **{info['filename']}** ({info['size']})")
        print(f"   - ì›ë³¸: {info['filename'].replace('_sample.json', '')}")

# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼
script_files = sorted(Path('.').glob('*.py'))
if script_files:
    print("\n\n## ğŸ”§ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ëª©ë¡\n")
    for script in script_files:
        size = os.path.getsize(script) / 1024
        print(f"ğŸ“œ **{script.name}** ({size:.1f} KB)")
        # ì²« ì¤„ docstring ì½ê¸°
        try:
            with open(script, encoding='utf-8') as f:
                lines = f.readlines()
                for line in lines:
                    if '"""' in line or "'''" in line:
                        desc_line = line.strip().strip('"""').strip("'''")
                        if desc_line:
                            print(f"   - {desc_line}")
                        break
                    elif line.strip().startswith('#') and 'coding' not in line:
                        print(f"   - {line.strip().lstrip('#').strip()}")
                        break
        except:
            pass

print("\n\n" + "=" * 100)
print("ìƒ‰ì¸ ìƒì„± ì™„ë£Œ!")
print("=" * 100)

# ê¶Œì¥ ì‚¬ìš© íŒŒì¼
print("\n## âœ… ê¶Œì¥ ì‚¬ìš© íŒŒì¼\n")
print("ğŸ¯ **anticancer_normalized_v2.csv** (ë˜ëŠ” .json)")
print("   - ê°€ì¥ ìµœì‹ ì´ë©° ì™„ì „í•œ ë°ì´í„°")
print("   - HIRA dictionary ì¡°ì¸ ì™„ë£Œ")
print("   - ì œì¡°ì‚¬, ì•½ê°€, íˆ¬ì—¬ê²½ë¡œ ì •ë³´ í¬í•¨")
print("   - 1,001ê°œ ì œí’ˆ, 154ê°œ ì„±ë¶„")
print("\nğŸ’¡ **ì‚¬ìš© ì˜ˆì‹œ**:")
print("   - í•­ì•”ì œ ê²€ìƒ‰/ì¡°íšŒ ì‹œìŠ¤í…œ")
print("   - ì•½ê°€ ë¹„êµ ë¶„ì„")
print("   - ì œì¡°ì‚¬ë³„ ì œí’ˆ í˜„í™©")
print("   - ATC ì½”ë“œ ê¸°ë°˜ ë¶„ë¥˜")
