"""ê·œì¹™ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ (Rule-based Entity Extraction)

Markdown íŒŒì‹± ê²°ê³¼ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
- LLM ì—†ì´ ì •ê·œì‹ + íŒ¨í„´ ë§¤ì¹­
- ì™„ì „ ë¬´ë£Œ, ë¹ ë¦„
"""
import json
import re
import sys
import codecs
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict

# Windows UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')


class RuleBasedEntityExtractor:
    """ê·œì¹™ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œê¸°"""

    def __init__(self):
        self.entities = defaultdict(list)
        self.relations = []

    def extract_from_file(self, parsed_json_path: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì‹± íŒŒì¼ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ"""
        with open(parsed_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        content = data.get('content', '')
        metadata = data.get('attachment_metadata', {})

        result = {
            'metadata': metadata,
            'entities': {},
            'relations': []
        }

        # 1. ì•”ì¢…ë¥˜ ì¶”ì¶œ
        cancers = self.extract_cancers(content)
        result['entities']['cancers'] = cancers

        # 2. ì•½ì œ ì •ë³´ ì¶”ì¶œ (í‘œì—ì„œ)
        drugs = self.extract_drugs_from_tables(content)
        result['entities']['drugs'] = drugs

        # 3. ì œí•œì‚¬í•­ ì¶”ì¶œ
        restrictions = self.extract_restrictions(content)
        result['entities']['restrictions'] = restrictions

        # 4. Q&A ì¶”ì¶œ
        qas = self.extract_qas(content)
        result['entities']['qas'] = qas

        # 5. ê´€ê³„ ìƒì„±
        result['relations'] = self.generate_relations(result['entities'], metadata)

        return result

    def extract_cancers(self, content: str) -> List[Dict[str, str]]:
        """ì•”ì¢…ë¥˜ ì¶”ì¶œ

        íŒ¨í„´: [ìˆ«ì] ì•”ì¢…ë¥˜ëª…(ì˜ë¬¸ëª…)
        ì˜ˆ: [28] ë¹„í˜¸ì§€í‚¨ë¦¼í”„ì¢…(Non-Hodgkin's Lymphoma)
        """
        cancers = []
        pattern = r'\[(\d+)\]\s*([^\(]+)\(([^\)]+)\)'

        for match in re.finditer(pattern, content):
            cancer_id = match.group(1)
            korean_name = match.group(2).strip()
            english_name = match.group(3).strip()

            cancers.append({
                'id': cancer_id,
                'korean_name': korean_name,
                'english_name': english_name,
                'code': f'CANCER_{cancer_id}'
            })

        return cancers

    def extract_drugs_from_tables(self, content: str) -> List[Dict[str, Any]]:
        """Markdown í‘œì—ì„œ ì•½ì œ ì •ë³´ ì¶”ì¶œ

        í‘œ í˜•ì‹:
        | ì—°ë²ˆ | í•­ì•”ìš”ë²• | íˆ¬ì—¬ëŒ€ìƒ | íˆ¬ì—¬ë‹¨ê³„ |
        | 18 | tisagenlecleucelì£¼ | ... | 3ì°¨ ì´ìƒ |
        """
        drugs = []

        # ê°œì„ ëœ í‘œ íŒŒì‹±: ì¤„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        lines = content.split('\n')

        i = 0
        while i < len(lines):
            line = lines[i].strip()

            # í‘œ í—¤ë” ì°¾ê¸°
            if line.startswith('|') and 'í•­ì•”ìš”ë²•' in line:
                headers = [h.strip() for h in line.split('|')[1:-1]]

                # êµ¬ë¶„ì„  ê±´ë„ˆë›°ê¸°
                i += 1
                if i >= len(lines):
                    break

                # ë°ì´í„° í–‰ íŒŒì‹±
                i += 1
                while i < len(lines):
                    data_line = lines[i].strip()

                    if not data_line.startswith('|'):
                        break

                    # ë¹ˆ í–‰ ì²´í¬
                    if data_line == '|':
                        i += 1
                        continue

                    cells = [c.strip() for c in data_line.split('|')[1:-1]]

                    # ì…€ ê°œìˆ˜ ì²´í¬ (ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
                    if len(cells) < len(headers):
                        # ë¹ˆ ì…€ ì¶”ê°€
                        cells.extend([''] * (len(headers) - len(cells)))
                    elif len(cells) > len(headers):
                        # ì´ˆê³¼ ì…€ ì œê±°
                        cells = cells[:len(headers)]

                    row_data = dict(zip(headers, cells))

                    # ì•½ì œëª… ì¶”ì¶œ
                    drug_raw = row_data.get('í•­ì•”ìš”ë²•', '').strip()

                    if drug_raw and drug_raw != '---':
                        # ì£¼ì„ ë²ˆí˜¸ ì œê±° (ì˜ˆ: "tisagenlecleucelì£¼ 6ì£¼ 7" â†’ "tisagenlecleucelì£¼")
                        # íŒ¨í„´: ìˆ«ì + "ì£¼" ë°˜ë³µ ì œê±°
                        drug_clean = re.sub(r'\s+\d+(?:ì£¼\s*\d+)*$', '', drug_raw).strip()

                        drug_info = {
                            'name': drug_clean,
                            'indication': row_data.get('íˆ¬ì—¬ëŒ€ìƒ', ''),
                            'line': row_data.get('íˆ¬ì—¬ë‹¨ê³„', ''),
                            'regimen': row_data.get('íˆ¬ì—¬ìš”ë²•', '-'),
                            'raw_name': drug_raw
                        }

                        drugs.append(drug_info)

                    i += 1

            i += 1

        return drugs

    def extract_restrictions(self, content: str) -> List[Dict[str, str]]:
        """ì œí•œì‚¬í•­ ì¶”ì¶œ

        íŒ¨í„´:
        - â–ª ê¸‰ì—¬ì¸ì • ê¸°ê°„: ...
        - ì£¼6. CAR-T ì„¸í¬ì¹˜ë£Œì œ...
        """
        restrictions = []

        # â–ª íŒ¨í„´ (bullet point)
        bullet_pattern = r'â–ª\s*([^:]+):\s*([^\n]+(?:\n(?!â–ª)[^\n]+)*)'
        for match in re.finditer(bullet_pattern, content):
            category = match.group(1).strip()
            description = match.group(2).strip()

            restrictions.append({
                'type': 'guideline',
                'category': category,
                'description': description
            })

        # ì£¼ì„ íŒ¨í„´
        note_pattern = r'ì£¼(\d+)\.\s*([^\n]+(?:\n(?!ì£¼\d)[^\n]+)*)'
        for match in re.finditer(note_pattern, content):
            note_id = match.group(1)
            description = match.group(2).strip()

            restrictions.append({
                'type': 'note',
                'note_id': f'ì£¼{note_id}',
                'description': description
            })

        return restrictions

    def extract_qas(self, content: str) -> List[Dict[str, str]]:
        """Q&A ì¶”ì¶œ

        íŒ¨í„´:
        # ì§ˆë¬¸ 1 íˆ¬ì—¬ëŒ€ìƒ ê¸°ì¤€ ì‹œì ì€...
        # <ë‹µë³€>
        â—‹ ì•½ë¬¼ íˆ¬ì… ì „ì´...
        """
        qas = []

        # ì§ˆë¬¸ íŒ¨í„´
        qa_pattern = r'ì§ˆë¬¸\s*(\d+)\s+([^\n]+)\n+#\s*<ë‹µë³€>\s*\n+(â—‹\s*[^\n]+(?:\n[^\n#]+)*)'

        for match in re.finditer(qa_pattern, content):
            question_id = match.group(1)
            question = match.group(2).strip()
            answer = match.group(3).strip()

            # ë‹µë³€ì—ì„œ â—‹ ì œê±°
            answer_clean = re.sub(r'^â—‹\s*', '', answer).strip()

            qas.append({
                'question_id': question_id,
                'question': question,
                'answer': answer_clean
            })

        return qas

    def generate_relations(self, entities: Dict[str, List], metadata: Dict) -> List[Dict[str, str]]:
        """ì—”í‹°í‹° ê°„ ê´€ê³„ ìƒì„±"""
        relations = []

        # Drug â†’ Cancer (TREATS)
        for drug in entities.get('drugs', []):
            for cancer in entities.get('cancers', []):
                # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: ê°™ì€ ë¬¸ì„œì— ìˆìœ¼ë©´ ê´€ë ¨
                relations.append({
                    'type': 'TREATS',
                    'source': drug['name'],
                    'source_type': 'Drug',
                    'target': cancer['korean_name'],
                    'target_type': 'Cancer',
                    'properties': {
                        'indication': drug['indication'],
                        'line': drug['line']
                    }
                })

        # Drug â†’ Document (MENTIONED_IN)
        for drug in entities.get('drugs', []):
            relations.append({
                'type': 'MENTIONED_IN',
                'source': drug['name'],
                'source_type': 'Drug',
                'target': metadata.get('post_number', 'UNKNOWN'),
                'target_type': 'Document',
                'properties': {
                    'board': metadata.get('board'),
                    'title': metadata.get('post_title', '')
                }
            })

        return relations


def main():
    """ìƒ˜í”Œ í…ŒìŠ¤íŠ¸"""
    extractor = RuleBasedEntityExtractor()

    # ìƒ˜í”Œ íŒŒì¼ ê²½ë¡œ
    sample_file = Path('data/hira_cancer/parsed_preview/faq_117.txt')

    if not sample_file.exists():
        print(f"âŒ ìƒ˜í”Œ íŒŒì¼ ì—†ìŒ: {sample_file}")
        return

    # í…ìŠ¤íŠ¸ íŒŒì¼ì„ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì„ì‹œ)
    with open(sample_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # Markdown ë‚´ìš©ë§Œ ì¶”ì¶œ
    markdown_start = content.find('[íŒŒì‹±ëœ Markdown ë‚´ìš©]')
    if markdown_start != -1:
        markdown_content = content[markdown_start + len('[íŒŒì‹±ëœ Markdown ë‚´ìš©]'):].strip()
    else:
        markdown_content = content

    # ì„ì‹œ ë°ì´í„° êµ¬ì¡°
    temp_data = {
        'content': markdown_content,
        'attachment_metadata': {
            'board': 'faq',
            'post_number': '117',
            'post_title': 'Tisagenlecleucel(í’ˆëª…: í‚´ë¦¬ì•„ì£¼) ê´€ë ¨ ì§ˆì˜ ì‘ë‹µ'
        }
    }

    # ì„ì‹œ JSON ì €ì¥
    temp_json = Path('temp_test.json')
    with open(temp_json, 'w', encoding='utf-8') as f:
        json.dump(temp_data, f, ensure_ascii=False, indent=2)

    # ì¶”ì¶œ ì‹¤í–‰
    result = extractor.extract_from_file(temp_json)

    # ê²°ê³¼ ì¶œë ¥
    print('=' * 80)
    print('ğŸ” ê·œì¹™ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ ê²°ê³¼')
    print('=' * 80)

    print('\nğŸ“Œ ì•”ì¢…ë¥˜ (Cancers):')
    for cancer in result['entities']['cancers']:
        print(f"  - [{cancer['id']}] {cancer['korean_name']} ({cancer['english_name']})")

    print('\nğŸ’Š ì•½ì œ ì •ë³´ (Drugs):')
    for drug in result['entities']['drugs']:
        print(f"  - {drug['name']}")
        print(f"    íˆ¬ì—¬ëŒ€ìƒ: {drug['indication'][:50]}...")
        print(f"    íˆ¬ì—¬ë‹¨ê³„: {drug['line']}")

    print('\nâš ï¸ ì œí•œì‚¬í•­ (Restrictions):')
    for i, restriction in enumerate(result['entities']['restrictions'][:5], 1):
        print(f"  {i}. [{restriction['type']}] {restriction.get('category', restriction.get('note_id', ''))}")
        print(f"     {restriction['description'][:60]}...")

    print('\nâ“ Q&A:')
    for qa in result['entities']['qas']:
        print(f"  Q{qa['question_id']}: {qa['question']}")
        print(f"  A: {qa['answer'][:80]}...")

    print('\nğŸ”— ê´€ê³„ (Relations):')
    for i, rel in enumerate(result['relations'][:5], 1):
        print(f"  {i}. ({rel['source']}) -[{rel['type']}]-> ({rel['target']})")

    print(f"\nâœ… ì´ ì¶”ì¶œ: {len(result['entities']['cancers'])}ê°œ ì•”ì¢…ë¥˜, "
          f"{len(result['entities']['drugs'])}ê°œ ì•½ì œ, "
          f"{len(result['entities']['restrictions'])}ê°œ ì œí•œì‚¬í•­, "
          f"{len(result['entities']['qas'])}ê°œ Q&A, "
          f"{len(result['relations'])}ê°œ ê´€ê³„")

    # ê²°ê³¼ ì €ì¥
    output_file = Path('data/hira_cancer/extracted_entities_sample.json')
    output_file.parent.mkdir(exist_ok=True, parents=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ì €ì¥: {output_file}")

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    temp_json.unlink()


if __name__ == '__main__':
    main()
